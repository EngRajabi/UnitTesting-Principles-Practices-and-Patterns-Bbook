<div dir="rtl">
67

  

چهار رکن یک Unit Test خوب

  

حالا به قلب موضوع می‌رسیم. در فصل 1، با ویژگی‌های یک مجموعه تست یونیت خوب آشنا شدید:

  

- این تست‌ها در چرخه توسعه یکپارچه شده‌اند. شما فقط زمانی از تست‌ها بهره‌مند می‌شوید که به طور فعال از آنها استفاده کنید؛ در غیر این صورت نوشتن آنها فایده‌ای ندارد.

- این تست‌ها فقط بخش‌های مهم کد شما را هدف قرار می‌دهند. همه کدهای تولیدی شایسته توجه یکسانی نیستند. تفکیک قلب برنامه (مدل دامنه آن) از سایر بخش‌ها بسیار مهم است. این موضوع در فصل 7 بررسی می‌شود.

- این تست‌ها حداکثر ارزش را با حداقل هزینه‌های نگهداری فراهم می‌کنند. برای دستیابی به این ویژگی آخر، باید بتوانید:

- یک تست با ارزش را شناسایی کنید (و به تبع آن، یک تست با ارزش کم را)

- یک تست با ارزش بنویسید

  

68

  

همانطور که در فصل 1 بحث کردیم، تشخیص یک تست با ارزش و نوشتن یک تست با ارزش دو مهارت جداگانه هستند. با این حال، مهارت دوم نیازمند مهارت اول است؛ بنابراین، در این فصل، نحوه تشخیص یک تست با ارزش را نشان خواهم داد. شما یک چارچوب مرجع جهانی را خواهید دید که با آن می‌توانید هر تستی را در مجموعه تحلیل کنید. سپس از این چارچوب مرجع برای مرور برخی مفاهیم محبوب تست یونیت استفاده خواهیم کرد: هرم تست و تست جعبه سیاه در مقابل تست جعبه سفید. کمربندها را ببندید: شروع می‌کنیم.

  

4\.1 فرو رفتن در چهار رکن یک Unit Test خوب یک Unit Test خوب دارای چهار ویژگی زیر است:

  

- حفاظت در برابر regression

- مقاومت در برابر refactoring

- بازخورد سریع

- قابلیت نگهداری

  

این چهار ویژگی اساسی هستند. شما می‌توانید از آنها برای تحلیل هر تست خودکار استفاده کنید، چه Unit، integration، یا end-to-end. هر تستی به درجه‌ای از هر ویژگی اشاره می‌کند. در این بخش، دو ویژگی اول را تعریف می‌کنم؛ و در بخش 4.2، ارتباط ذاتی بین آنها را توضیح می‌دهم.

  

4\.1.1 رکن اول: حفاظت در برابر regressionها بیایید با اولین ویژگی یک Unit Test خوب شروع کنیم: حفاظت در برابر regressionها. همانطور که از فصل 1 می‌دانید، یک regression یک باگ نرم‌افزاری است. این زمانی اتفاق می‌افتد که یک ویژگی پس از انجام تغییراتی در کد، معمولاً پس از پیاده‌سازی یک قابلیت جدید، دیگر به درستی کار نمی‌کند.

  

این regressionها آزاردهنده هستند (حداقل می‌توان این را گفت)، اما این بدترین قسمت آن‌ها نیست. بدترین قسمت این است که هرچه ویژگی‌های بیشتری توسعه دهید، احتمال بیشتری وجود دارد که یکی از آن ویژگی‌ها را با انتشار نسخه جدید خراب کنید. یک واقعیت ناخوشایند از زندگی برنامه‌نویسی این است که کد یک دارایی نیست، بلکه یک مسئولیت است. هرچه پایه کد بزرگتر باشد، احتمال بیشتری برای وقوع باگ‌ها دارد. به همین دلیل توسعه یک حفاظت خوب در برابر regressionها بسیار مهم است. بدون چنین حفاظتی، نمی‌توانید رشد پروژه را در طولانی مدت حفظ کنید – شما زیر بار تعداد باگ‌های همیشه در حال افزایش دفن خواهید شد.

  

برای ارزیابی اینکه یک تست تا چه حد در حفاظت در برابر regressionها موفق است، باید موارد زیر را در نظر بگیرید:

  

- میزان کدی که در طول تست اجرا می‌شود

- پیچیدگی آن کد

- اهمیت حوزه آن کد

  

به طور کلی، هرچه میزان کد بیشتری در طول تست اجرا شود، احتمال بیشتری وجود دارد که تست یک regression را آشکار کند. البته، به شرطی که این تست مجموعه‌ای مرتبط از assertionها داشته باشد، شما نمی‌خواهید تنها کد را اجرا کنید. در حالی که دانستن اینکه این کد بدون انداختن exception اجرا می‌شود مفید است، شما همچنین باید نتیجه‌ای که تولید می‌کند را تأیید کنید.

  

68

  

توجه داشته باشید که تنها میزان کد مهم نیست، بلکه پیچیدگی و اهمیت حوزه آن نیز اهمیت دارد. کدی که منطق کسب‌وکاری پیچیده‌ای را نمایندگی می‌کند، مهم‌تر از کدهای boilerplate است—باگ‌ها در قابلیت‌های حیاتی کسب‌وکار بیشترین آسیب را می‌رسانند. از طرف دیگر، معمولاً تست کدهای پیش پا افتاده ارزش چندانی ندارد. این نوع کدها کوتاه هستند و منطق کسب‌وکار قابل توجهی ندارند. تست‌هایی که کدهای پیش پا افتاده را پوشش می‌دهند، شانس زیادی برای پیدا کردن خطای regression ندارند، زیرا فضای زیادی برای اشتباه وجود ندارد. یک مثال از کد پیش پا افتاده، یک property تک خطی مانند این است:

  

public class User

  

{

  

` `public string Name { get; set; }

  

}

  

علاوه بر کدی که شما نوشته‌اید، کدی که شما ننوشته‌اید نیز اهمیت دارد: برای مثال، کتابخانه‌ها، فریم‌ورک‌ها، و هر سیستم خارجی که در پروژه استفاده می‌شود. آن کد تقریباً به اندازه کد خود شما بر عملکرد نرم‌افزار تأثیر می‌گذارد. برای بهترین حفاظت، تست باید شامل این کتابخانه‌ها، فریم‌ورک‌ها و سیستم‌های خارجی در دامنه تست باشد، تا بررسی کند که فرضیاتی که نرم‌افزار شما در مورد این وابستگی‌ها می‌کند صحیح هستند.

  

نکته: برای به حداکثر رساندن معیار حفاظت در برابر regressionها، تست باید هدفش را بر اجرای بیشترین مقدار کد ممکن قرار دهد.

  

رکن دوم: مقاومت در برابر refactoring دومین ویژگی یک Unit Test خوب مقاومت در برابر refactoring است – درجه‌ای که یک تست می‌تواند بدون خراب شدن (قرمز شدن) در برابر تغییرات refactoring در کدهای اصلی برنامه دوام بیاورد.

  

تعریف: Refactoring به معنای تغییر کد موجود بدون تغییر در رفتار قابل مشاهده آن است. هدف معمولاً بهبود ویژگی‌های غیرعملکردی کد است: افزایش خوانایی و کاهش پیچیدگی. برخی از مثال‌های refactoring شامل تغییر نام یک متد و استخراج یک قطعه کد به یک کلاس جدید هستند.

  

این وضعیت را تصور کنید. شما یک قابلیت جدید توسعه داده‌اید و همه چیز عالی کار می‌کند. خود قابلیت به درستی کار خود را انجام می‌دهد و تمام تست‌ها پاس می‌شوند. حالا تصمیم می‌گیرید کد را تمیز کنید. مقداری refactoring اینجا، کمی تغییرات آنجا، و همه چیز حتی بهتر از قبل به نظر می‌رسد. به جز یک مورد – تست‌ها خراب شده‌اند. شما دقیق‌تر نگاه می‌کنید تا ببینید دقیقاً چه چیزی را با refactoring خراب کرده‌اید، اما متوجه می‌شوید که هیچ چیزی را خراب نکرده‌اید. قابلیت به درستی و دقیقاً مانند قبل کار می‌کند. مشکل این است که تست‌ها به گونه‌ای نوشته شده‌اند که با هر تغییری در کدهای اصلی خراب می‌شوند. و این کار را بدون توجه به اینکه آیا واقعاً قابلیت خراب شده است یا نه، انجام می‌دهند.

  

این وضعیت را یک "مثبت کاذب" می‌نامند. یک مثبت کاذب یک هشدار نادرست است. این نتیجه‌ای است که نشان می‌دهد تست خراب است، اگرچه در واقعیت، قابلیتی که تست آن را پوشش می‌دهد به درستی کار می‌کند.

  

**70**

  

وقتی کد را refactor می‌کنید، تغییرات در پیاده‌سازی را اعمال می‌کنید اما رفتار قابل مشاهده را دست‌نخورده نگه می‌دارید. از این رو نام این ویژگی یک Unit Test خوب "مقاومت در برابر refactoring" است. برای ارزیابی اینکه یک تست تا چه حد در مقاومت در برابر refactoring موفق است، باید به تعداد مثبت‌های کاذب که تست تولید می‌کند توجه کنید. هرچه کمتر، بهتر.

  

چرا این همه توجه به مثبت‌های کاذب؟ چون آنها می‌توانند تأثیر مخربی بر کل مجموعه تست شما داشته باشند. همانطور که از فصل 1 به خاطر دارید، هدف تست‌های واحد (unit testing) ایجاد امکان رشد پایدار پروژه است. مکانیزمی که از طریق آن تست‌ها این رشد پایدار را ممکن می‌سازند، این است که به شما اجازه می‌دهند ویژگی‌های جدیدی اضافه کنید و refactoringهای منظم را بدون ایجاد regression انجام دهید. دو مزیت خاص در اینجا وجود دارد:

  

- تست‌ها هشدار زودهنگامی ارائه می‌دهند وقتی که قابلیت‌های موجود را خراب کنید. با تشکر از چنین هشدارهای زودهنگام، می‌توانید یک مشکل را خیلی قبل از اینکه کد معیوب به تولید برسد، برطرف کنید، جایی که برخورد با آن نیازمند تلاش بسیار بیشتری خواهد بود.

- شما مطمئن می‌شوید که تغییرات کد شما منجر به regression نمی‌شوند. بدون چنین اطمینانی، شما تمایل بیشتری به انجام refactoring نخواهید داشت و احتمال بیشتری وجود دارد که کد پایه (code base) را به حال خود رها کنید تا دچار خرابی شود.

  

مثبت‌های کاذب با هر دوی این مزایا تداخل می‌کنند:

  

- اگر تست‌ها بدون دلیل موجه خراب شوند، توانایی و تمایل شما به واکنش به مشکلات کد کاهش می‌یابد. با گذشت زمان، به چنین خرابی‌هایی عادت می‌کنید و توجه کمتری به آنها می‌کنید. پس از مدتی، شروع به نادیده گرفتن خرابی‌های واقعی نیز می‌کنید و اجازه می‌دهید آنها به تولید راه پیدا کنند.

- از سوی دیگر، وقتی مثبت‌های کاذب زیاد هستند، به تدریج اعتماد به مجموعه تست را از دست می‌دهید. شما دیگر آن را به عنوان یک شبکه ایمنی قابل اعتماد در نظر نمی‌گیرید – این ادراک با هشدارهای کاذب کاهش می‌یابد. این عدم اعتماد منجر به کاهش تعداد refactoringها می‌شود، زیرا شما سعی می‌کنید تغییرات کد را به حداقل برسانید تا از regression جلوگیری کنید.

- داستانی از میدان تجربه

-  ` `یک بار روی پروژه‌ای کار می‌کردم که تاریخچه غنی داشت. پروژه خیلی قدیمی نبود، شاید دو یا سه سال؛ اما در طی این مدت، مدیریت به طور قابل توجهی جهت مورد نظرشان برای پروژه را تغییر دادند و توسعه نیز متناسب با آن تغییر کرد. در طول این تغییر، مشکلی بروز کرد: پایه کد حجم زیادی از کدهای باقی‌مانده را جمع‌آوری کرده بود که هیچ کس جرات حذف یا refactor آنها را نداشت. شرکت دیگر به قابلیت‌هایی که آن کد ارائه می‌داد نیاز نداشت، اما برخی قسمت‌های آن در قابلیت‌های جدید استفاده می‌شد، بنابراین امکان حذف کامل کدهای قدیمی وجود نداشت.

- پروژه پوشش تست خوبی داشت. اما هر بار که کسی سعی می‌کرد قابلیت‌های قدیمی را refactor کند و قسمت‌هایی که هنوز استفاده می‌شد را از سایر قسمت‌ها جدا کند، تست‌ها خراب می‌شدند. و نه فقط تست‌های قدیمی – آنها مدت‌ها پیش غیرفعال شده بودند – بلکه تست‌های جدید هم خراب می‌شدند. برخی از خرابی‌ها واقعی بودند، اما بیشتر آنها نبودند – آنها مثبت‌های کاذب بودند.

- در این شرایط، وجود مثبت‌های کاذب باعث می‌شد که برنامه‌نویسان از انجام تغییرات و بهبود کد هراس داشته باشند، چون هر تغییری ممکن بود باعث خراب شدن تست‌ها شود و اطمینان به مجموعه تست کاهش یابد. این به نوبه خود منجر به عدم تمایل به انجام refactoring و در نتیجه تجمع بیشتر کدهای قدیمی و ناکارآمد می‌شد.

  

**71**

  

در ابتدا، توسعه‌دهندگان تلاش کردند تا با خرابی‌های تست‌ها مقابله کنند. اما از آنجا که اکثریت عظیم آنها هشدارهای نادرست بودند، وضعیت به نقطه‌ای رسید که توسعه‌دهندگان این خرابی‌ها را نادیده گرفتند و تست‌های خراب را غیرفعال کردند. نگرش غالب این بود که، "اگر به خاطر آن کد قدیمی است، فقط تست را غیرفعال کن؛ بعداً به آن نگاه می‌کنیم." همه چیز برای مدتی خوب کار می‌کرد – تا اینکه یک باگ بزرگ به تولید نفوذ کرد. یکی از تست‌ها به درستی باگ را شناسایی کرده بود، اما کسی توجه نکرد؛ آن تست همراه با بقیه غیرفعال شده بود. پس از آن حادثه، توسعه‌دهندگان به طور کلی کدهای قدیمی را دست‌نخورده باقی گذاشتند.

  

این داستان برای اکثر پروژه‌هایی که تست‌های شکننده دارند، معمول است. در ابتدا، توسعه‌دهندگان خرابی‌های تست‌ها را به‌صورت ظاهری می‌پذیرند و با آنها برخورد می‌کنند. پس از مدتی، افراد از تست‌هایی که همیشه "گرگ" می‌گویند خسته می‌شوند و شروع به نادیده گرفتن آنها می‌کنند. در نهایت، لحظه‌ای فرا می‌رسد که تعدادی باگ واقعی به تولید منتقل می‌شود چون توسعه‌دهندگان خرابی‌ها را همراه با تمام مثبت‌های کاذب نادیده گرفته‌اند.

  

شما نمی‌خواهید به چنین وضعیتی با متوقف کردن تمام refactoring‌ها واکنش نشان دهید. پاسخ درست این است که مجموعه تست را دوباره ارزیابی کرده و شکنندگی آن را کاهش دهید. این موضوع را در فصل 7 پوشش می‌دهم.

  

\### 4.1.3 چه چیزی باعث مثبت‌های کاذب می‌شود؟

  

پس، چه چیزی باعث مثبت‌های کاذب می‌شود؟ و چگونه می‌توانید از آنها جلوگیری کنید؟

  

تعداد مثبت‌های کاذب تولید شده توسط یک تست به طور مستقیم به نحوه ساختاردهی تست بستگی دارد. هر چه تست بیشتر به جزئیات پیاده‌سازی سیستم تحت تست (SUT) متصل باشد، تعداد هشدارهای نادرست بیشتری تولید می‌کند. تنها راه کاهش احتمال دریافت یک مثبت کاذب این است که تست را از آن جزئیات پیاده‌سازی جدا کنید. باید مطمئن شوید که تست نتیجه نهایی‌ای که SUT تحویل می‌دهد را تأیید می‌کند: رفتار قابل مشاهده آن، نه مراحل انجام آن. تست‌ها باید به تأیید SUT از دید کاربر نهایی نزدیک شوند و فقط نتیجه‌ای که برای آن کاربر نهایی معنادار است را بررسی کنند. همه چیزهای دیگر باید نادیده گرفته شوند (بیشتر در این مورد در فصل 5).

  

بهترین راه برای ساختاردهی یک تست این است که داستانی درباره دامنه مسئله بگوید. اگر چنین تستی شکست بخورد، آن شکست به معنای عدم تطابق بین داستان و رفتار واقعی برنامه است. این تنها نوع شکست تست است که به شما سود می‌رساند – چنین شکست‌هایی همیشه به نقطه درست اشاره می‌کنند و به شما کمک می‌کنند سریعاً بفهمید چه چیزی اشتباه شده است. تمام شکست‌های دیگر فقط نویز هستند که توجه شما را از موارد مهم دور می‌کنند.

  

به مثال زیر نگاهی بیندازید. در آن، کلاس MessageRenderer نمای HTML از یک پیام شامل سرصفحه، بدنه و پانوشت را تولید می‌کند.

  
```c#
public class Message
{
public string Header { get; set; }
public string Body { get; set; }
public string Footer { get; set; }
}
```
  

**72**

  
```c#
public interface IRenderer
{
string Render(Message message);
}
```
```c#
public class MessageRenderer : IRenderer
{
public IReadOnlyList<IRenderer> SubRenderers { get; }
public MessageRenderer()
{
SubRenderers = new List<IRenderer>
{
new HeaderRenderer(),
new BodyRenderer(),
new FooterRenderer()
};
}
public string Render(Message message)
{
return SubRenderers
.Select(x => x.Render(message))
.Aggregate("", (str1, str2) => str1 + str2);
}
}
```

کلاس `MessageRenderer` شامل چندین زیر-رندرر است که به آنها وظیفه واقعی پردازش بخش‌های مختلف پیام را واگذار می‌کند. سپس نتیجه را به یک سند HTML ترکیب می‌کند. زیر-رندررها متن خام را با تگ‌های HTML هماهنگ می‌کنند. به عنوان مثال:

  
```c#
public class BodyRenderer : IRenderer
{
public string Render(Message message)
{
return $"<b>{message.Body}</b>";
}
}
```
چگونه می‌توان `MessageRenderer` را تست کرد؟ یکی از رویکردهای ممکن، تحلیل الگوریتمی است که این کلاس دنبال می‌کند.

**فهرست 4.2: تأیید اینکه MessageRenderer ساختار صحیحی دارد**
```c#
[Fact]
public void MessageRenderer\_uses\_correct\_sub\_renderers()
{
var sut = new MessageRenderer();
IReadOnlyList<IRenderer> renderers = sut.SubRenderers;
Listing 4.2 Verifying that **MessageRenderer** has the correct structure
***Diving into the four pillars of a good unit test* 73**
Assert.Equal(3, renderers.Count);
Assert.IsAssignableFrom<HeaderRenderer>(renderers[0]);
Assert.IsAssignableFrom<BodyRenderer>(renderers[1]);
Assert.IsAssignableFrom<FooterRenderer>(renderers[2]);
}
  ```

این تست بررسی می‌کند که آیا زیر-رندررها همه از نوع‌های مورد انتظار هستند و به ترتیب صحیح ظاهر می‌شوند، که این فرض را دارد که روش پردازش پیام‌ها توسط `MessageRenderer` نیز باید صحیح باشد. تست ممکن است در ابتدا خوب به نظر برسد، اما آیا واقعاً رفتار قابل مشاهده `MessageRenderer` را تأیید می‌کند؟ اگر زیر-رندررها را جابه‌جا کنید یا یکی از آنها را با جدیدی جایگزین کنید، آیا این می‌تواند منجر به بروز یک باگ شود؟

نه لزوماً. شما می‌توانید ترکیب زیر-رندررها را به گونه‌ای تغییر دهید که سند HTML نهایی همانند قبل باقی بماند. برای مثال، می‌توانید `BodyRenderer` را با `BoldRenderer` جایگزین کنید که همان کار `BodyRenderer` را انجام می‌دهد. یا می‌توانید تمام زیر-رندررها را حذف کرده و رندر کردن را مستقیماً در `MessageRenderer` پیاده‌سازی کنید.

 <p align="center">
    <img src="../Part 4/Images/4.1.png" />
</p>

با این حال، در صورت انجام هر یک از این تغییرات، تست خراب خواهد شد، حتی اگر نتیجه نهایی تغییر نکند. این به این دلیل است که تست به جزئیات پیاده‌سازی SUT وابسته است و نه به نتیجه‌ای که SUT تولید می‌کند. این تست الگوریتم را بررسی می‌کند و انتظار دارد که پیاده‌سازی خاصی را ببیند، بدون توجه به پیاده‌سازی‌های جایگزین که به همان اندازه قابل قبول هستند (نگاه کنید به شکل 4.1).

\*\*شکل 4.1: تستی که به الگوریتم SUT وابسته است\*\*

  
تست‌هایی که به الگوریتم SUT وابسته هستند، انتظار دارند که پیاده‌سازی خاصی را مشاهده کنند (مراحل مشخصی که SUT باید برای ارائه نتیجه انجام دهد) و به همین دلیل شکننده هستند. هرگونه refactoring در پیاده‌سازی SUT منجر به شکست تست خواهد شد.

هرگونه refactoring قابل توجه در کلاس `MessageRenderer` منجر به شکست تست خواهد شد. توجه داشته باشید که فرآیند refactoring تغییر پیاده‌سازی بدون تأثیر بر رفتار قابل مشاهده برنامه است. و به همین دلیل است که تست، به دلیل تمرکز بر جزئیات پیاده‌سازی، هر بار که این جزئیات تغییر می‌کند، به خطا می‌افتد.

**74** CHAPTER 4 ***The four pillars of a good unit test***

` `بنابراین، تست‌هایی که به جزئیات پیاده‌سازی SUT وابسته هستند، در برابر refactoring مقاوم نیستند. چنین تست‌هایی تمام معایبی را که قبلاً توضیح دادم، نشان می‌دهند:

- آنها هشدار زودهنگام در صورت بروز regressions ارائه نمی‌دهند—شما به سادگی این هشدارها را به دلیل عدم ارتباط کافی نادیده می‌گیرید.

- آنها توانایی و تمایل شما برای refactoring را محدود می‌کنند. تعجبی ندارد—چه کسی می‌خواهد refactor کند، وقتی که تست‌ها نمی‌توانند در یافتن باگ‌ها درست عمل کنند؟


فهرست بعدی بدترین مثال از شکنندگی در تست‌ها را که تاکنون دیده‌ام نشان می‌دهد، که در آن تست به کد منبع کلاس MessageRenderer می‌خواند و آن را با پیاده‌سازی "صحیح" مقایسه می‌کند.
```c#
<![endif]-->

[Fact]

public void MessageRenderer_is_implemented_correctly()

{

string sourceCode = File.ReadAllText(@"[path]\MessageRenderer.cs");

Assert.Equal(@"

public class MessageRenderer : IRenderer
{

public IReadOnlyList<<IRenderer> SubRenderers { get; }
public MessageRenderer()
{
SubRenderers = new List<<IRenderer>
{

new HeaderRenderer(),
new BodyRenderer(),
new FooterRenderer()
};
}
public string Render(Message message) { /* ... */ }
}", sourceCode);
}
  ```

البته، این تست کاملاً خنده‌دار است؛ با تغییر حتی جزئی‌ترین جزئیات در کلاس MessageRenderer شکست خواهد خورد. در عین حال، این تست از تستی که قبلاً مطرح کردم، تفاوت چندانی ندارد. هر دو بر یک پیاده‌سازی خاص اصرار دارند بدون اینکه رفتار قابل مشاهده SUT را در نظر بگیرند. و هر دو هر بار که آن پیاده‌سازی را تغییر دهید، به خطا خواهند افتاد. البته، تست در فهرست 4.3 احتمالاً بیشتر از تست در فهرست 4.2 خراب خواهد شد.

  
**4.1.4 به نتیجه نهایی توجه کنید به جای جزئیات پیاده‌سازی**

  

همانطور که قبلاً ذکر کردم، تنها راه برای جلوگیری از شکنندگی در تست‌ها و افزایش مقاومت آنها در برابر refactoring این است که آنها را از جزئیات پیاده‌سازی SUT جدا کنید—تا حد امکان فاصله بین تست و کارکردهای داخلی کد را حفظ کنید، و

  

***Diving into the four pillars of a good unit test* 75**

  

به جای تمرکز بر جزئیات پیاده‌سازی، باید به تأیید نتیجه نهایی بپردازید. بیایید این کار را انجام دهیم: تست موجود در فهرست 4.2 را به چیزی کمتر شکننده تغییر دهیم.

  

برای شروع، باید از خود بپرسید: نتیجه نهایی که از MessageRenderer دریافت می‌کنید چیست؟ خوب، این نمای HTML یک پیام است. و این تنها چیزی است که بررسی آن منطقی است، چون تنها نتیجه قابل مشاهده‌ای است که از این کلاس دریافت می‌کنید. تا زمانی که این نمای HTML ثابت بماند، نیازی به نگرانی درباره چگونگی تولید آن ندارید. چنین جزئیات پیاده‌سازی بی‌ربط هستند.

```c#
[Fact]

public void Rendering_a_message()
{
var sut = new MessageRenderer();

var message = new Message
{
Header = "h",
Body = "b",
Footer = "f"
};

string html = sut.Render(message);
Assert.Equal("<h1>h</h1><b>b</b><i>f</i>", html);
}
```

این تست `MessageRenderer` را به‌عنوان یک جعبه سیاه در نظر می‌گیرد و تنها به رفتار قابل مشاهده آن توجه دارد. در نتیجه، این تست مقاومت بیشتری در برابر refactoring دارد—فرقی نمی‌کند چه تغییراتی در SUT اعمال کنید به شرطی که خروجی HTML همانند قبل باقی بماند (شکل 4.2).

توجه کنید که چگونه این تست نسبت به نسخه اصلی به‌طور قابل توجهی بهبود یافته است. این تست با نیازهای کسب‌وکار هماهنگ است چرا که تنها نتیجه‌ای را بررسی می‌کند که برای کاربران نهایی معنا دارد—

\*\*شکل 4.2: تست در سمت چپ به رفتار قابل مشاهده SUT وابسته است، برخلاف جزئیات پیاده‌سازی. چنین تستی در برابر refactoring مقاوم است—کمتر باعث ایجاد false positives می‌شود.\*\*
<p align="center">
    <img src="../Part 4/Images/4.2.png" />
</p>



**76** CHAPTER 4 ***The four pillars of a good unit test***

  

چگونه یک پیام در مرورگر نمایش داده می‌شود. شکست‌های چنین تستی همیشه به نقطه نظر می‌زنند: آنها تغییر در رفتار برنامه را که می‌تواند بر مشتری تأثیر بگذارد، گزارش می‌کنند و بنابراین باید توجه توسعه‌دهنده را جلب کنند. این تست کمتر باعث ایجاد false positives می‌شود، اگر اصلاً ایجاد کند.
چرا کمتر و نه هیچ؟ زیرا ممکن است تغییراتی در `MessageRenderer` ایجاد شود که تست را بشکند. به عنوان مثال، ممکن است پارامتر جدیدی به متد `Render()` اضافه کنید که باعث خطای کامپایل شود. و از نظر تکنیکی، چنین خطایی نیز به‌عنوان false positive محسوب می‌شود. پس از همه، تست به دلیل تغییر در رفتار برنامه شکست نمی‌خورد.

اما این نوع false positive به راحتی قابل رفع است. کافی است با کامپایلر همراه شوید و پارامتر جدید را به تمام تست‌هایی که متد `Render()` را فراخوانی می‌کنند، اضافه کنید. بدترین false positive‌ها آنهایی هستند که منجر به خطای کامپایل نمی‌شوند. چنین false positive‌هایی سخت‌تر از همه قابل رفع هستند—به نظر می‌رسد که به یک باگ واقعی اشاره می‌کنند و نیاز به زمان بیشتری برای بررسی دارند.

\### 4.2 ارتباط ذاتی بین دو ویژگی اول
همانطور که قبلاً ذکر کردم، ارتباط ذاتی بین دو ستون اول تست‌های خوب—محافظت در برابر regressions و مقاومت در برابر refactoring—وجود دارد. هر دو به دقت تست مجموعه کمک می‌کنند، اگرچه از دیدگاه‌های مخالف. این دو ویژگی همچنین به طور متفاوتی بر پروژه تأثیر می‌گذارند: در حالی که داشتن محافظت خوب در برابر regressions بسیار مهم است، نیاز به مقاومت در برابر refactoring فوری نیست.
در این بخش، من در مورد موارد زیر صحبت می‌کنم:
\- حداکثر کردن دقت تست
\- اهمیت false positive‌ها و false negative‌ها

\### 4.2.1 حداکثر کردن دقت تست

بیایید یک قدم به عقب برگردیم و به تصویر کلی مربوط به نتایج تست نگاه کنیم. وقتی صحبت از درستی کد و نتایج تست به میان می‌آید، چهار نتیجه ممکن وجود دارد، همانطور که در شکل 4.3 نشان داده شده است. تست می‌تواند یا موفق باشد یا شکست بخورد (ردیف‌های جدول). و خود عملکرد می‌تواند یا درست یا معیوب باشد (ستون‌های جدول).
وضعیتی که در آن تست موفق است و عملکرد پایه‌ای به درستی کار می‌کند، نتیجه صحیح است: تست به درستی وضعیت سیستم را استنباط کرده است (هیچ باگی در آن وجود ندارد). اصطلاح دیگری برای این ترکیب از عملکرد کارکردی و تست موفق، true negative است.
به طور مشابه، زمانی که عملکرد معیوب است و تست شکست می‌خورد، این نیز یک نتیجه صحیح است. زیرا انتظار دارید که تست زمانی که عملکرد به درستی کار نمی‌کند، شکست بخورد. این همان هدف تست واحد است. اصطلاح مربوط به این وضعیت، true positive است.
اما زمانی که تست خطا را شناسایی نمی‌کند، این یک مشکل است. این وضعیت در ربع بالا-راست، false negative است. و این همان چیزی است که ویژگی اول تست خوب—محافظت در برابر regressions—به دنبال آن است.

***The intrinsic connection between the first two attributes* 77**

<p align="center">
    <img src="../Part 4/Images/4.3.png" />
</p>

\*\*شکل 4.3: ارتباط بین محافظت در برابر regressions و مقاومت در برابر refactoring. محافظت در برابر regressions از false negative‌ها (خطاهای نوع II) جلوگیری می‌کند. مقاومت در برابر refactoring تعداد false positive‌ها (خطاهای نوع I) را به حداقل می‌رساند.\*\*
\*\*محافظت در برابر regressions\*\* به شما کمک می‌کند تا از false negatives (خطاهای نوع II) جلوگیری کنید. تست‌هایی که محافظت خوبی در برابر regressions دارند، به شما کمک می‌کنند تا تعداد false negatives را به حداقل برسانید.
از سوی دیگر، وضعیتی معکوس وجود دارد که عملکرد صحیح است اما تست همچنان شکست می‌خورد. این یک false positive، یک هشدار کاذب است. و این همان چیزی است که ویژگی دوم—مقاومت در برابر refactoring—به شما کمک می‌کند.

تمام این اصطلاحات (false positive، خطای نوع I و غیره) ریشه در آمار دارند، اما می‌توانند برای تحلیل مجموعه تست نیز به کار روند. بهترین راه برای درک آن‌ها این است که به یک تست آنفولانزا فکر کنید. تست آنفولانزا مثبت است وقتی فردی که تست را انجام داده، آنفولانزا دارد.
اصطلاح مثبت ممکن است کمی گیج‌کننده باشد زیرا هیچ چیز مثبتی در داشتن آنفولانزا وجود ندارد. اما تست به طور کلی وضعیت را ارزیابی نمی‌کند. در زمینه تست، مثبت به معنای این است که مجموعه‌ای از شرایط اکنون درست است. این شرایطی است که سازندگان تست آن را برای واکنش تنظیم کرده‌اند. در این مثال خاص، وجود آنفولانزا است. به طور معکوس، عدم وجود آنفولانزا تست آنفولانزا را منفی می‌کند.
حال، وقتی دقت تست آنفولانزا را ارزیابی می‌کنید، اصطلاحات مانند false positive یا false negative را مطرح می‌کنید. احتمال false positives و false negatives به شما می‌گوید که تست آنفولانزا چقدر خوب است: هرچه این احتمال کمتر باشد، تست دقیق‌تر است.
این دقت همان چیزی است که دو ویژگی اول یک تست خوب به دنبال آن هستند. \*\*محافظت در برابر regressions\*\* و \*\*مقاومت در برابر refactoring\*\* به دنبال حداکثر کردن دقت مجموعه تست هستند. معیار دقت خود شامل دو جزء است:
\- چقدر تست در نشان دادن وجود باگ‌ها خوب است (عدم وجود false negatives، حوزه محافظت در برابر regressions)
\- چقدر تست در نشان دادن عدم وجود باگ‌ها خوب است (عدم وجود false positives، حوزه مقاومت در برابر refactoring)
راه دیگری برای تفکر در مورد false positives و false negatives در قالب نسبت سیگنال به نویز است. همانطور که در فرمول شکل 4.4 مشاهده می‌کنید، دو راه برای بهبود دقت تست وجود دارد:
**78** CHAPTER 4 ***The four pillars of a good unit test***
<p align="center">
    <img src="../Part 4/Images/4.4.png" />
</p>

دقت تست =نویز (تعداد هشدارهای کاذب ایجاد شده) تقسیم بر سیگنال (تعداد باگ‌های پیدا شده)
\*\*شکل 4.4: یک تست به اندازه‌ای دقیق است که بتواند سیگنال قوی (قادر به یافتن باگ‌ها) را با کمترین میزان نویز (هشدارهای کاذب) تولید کند.\*\*
\*\*دقت تست:\*\* اولین روش برای بهبود دقت، افزایش کسر، یعنی \*\*سیگنال\*\* است: یعنی تست را بهتر کنید تا باگ‌ها را پیدا کند. روش دوم کاهش مخرج، یعنی \*\*نویز\*\* است: تست را بهتر کنید تا هشدارهای کاذب را کاهش دهد.
هر دو به طور بحرانی مهم هستند. تستی که قادر به پیدا کردن هیچ باگی نباشد، حتی اگر هشدارهای کاذب تولید نکند، بی‌فایده است. به همین ترتیب، دقت تست زمانی به صفر می‌رسد که تست مقدار زیادی نویز تولید کند، حتی اگر قادر به یافتن تمام باگ‌های کد باشد. این یافته‌ها در دریای اطلاعات بی‌ربط گم می‌شوند.
\*\*اهمیت false positives و false negatives: دینامیک‌ها\*\*
در کوتاه‌مدت، false positives به اندازه false negatives بد نیستند. در آغاز یک پروژه، دریافت یک هشدار نادرست آنقدرها مهم نیست در مقایسه با عدم دریافت هشدار و خطر ورود یک باگ به تولید. اما با رشد پروژه، false positives تاثیر بیشتری بر روی مجموعه تست خواهند داشت (شکل 4.5).

  

\*\*شکل 4.5: هشدارهای کاذب (false positives) در ابتدای پروژه تأثیر منفی زیادی ندارند. اما با رشد پروژه، آن‌ها اهمیت بیشتری پیدا می‌کنند و به اندازه false negatives (باگ‌های نادیده گرفته شده) اهمیت پیدا می‌کنند.\*\*

<p align="center">
    <img src="../Part 4/Images/4.5.png" />
</p>

***The third and fourth pillars: Fast feedback and maintainability* 79**
چرا هشدارهای کاذب در ابتدا اهمیت زیادی ندارند؟ زیرا اهمیت بازآرایی (refactoring) نیز بلافاصله آشکار نمی‌شود و به تدریج افزایش می‌یابد. در آغاز پروژه، نیاز به انجام تمیزکاری‌های کد زیاد نیست. کد تازه نوشته شده معمولاً براق و بی‌عیب و نقص است و همچنین هنوز تازه در حافظه شما است، بنابراین می‌توانید به راحتی آن را بازآرایی کنید حتی اگر تست‌ها هشدارهای کاذب ایجاد کنند.

اما با گذشت زمان، کد پیچیده‌تر و نامنظم‌تر می‌شود. در نتیجه، باید به طور منظم بازآرایی‌ها را انجام دهید تا از این روند جلوگیری کنید. در غیر این صورت، هزینه اضافه کردن ویژگی‌های جدید در نهایت بسیار بالا خواهد رفت.
با افزایش نیاز به بازآرایی، اهمیت مقاومت تست‌ها در برابر بازآرایی نیز افزایش می‌یابد. همان‌طور که قبلاً توضیح دادم، وقتی تست‌ها دائماً هشدارهای کاذب می‌دهند و شما هشدارهای مربوط به باگ‌هایی که وجود ندارند را دریافت می‌کنید، نمی‌توانید بازآرایی کنید. سریعاً اعتماد خود را به چنین تست‌هایی از دست می‌دهید و دیگر آن‌ها را به عنوان منبع بازخورد قابل اطمینان نمی‌بینید.
با وجود اهمیت حفاظت از کد در برابر هشدارهای کاذب، به ویژه در مراحل بعدی پروژه، تعداد کمی از توسعه‌دهندگان به این شکل به هشدارهای کاذب توجه می‌کنند. اکثر افراد تنها بر بهبود اولین ویژگی یک تست خوب تمرکز می‌کنند—حفاظت در برابر رگرسیون، که برای ساختن یک مجموعه تست ارزشمند و بسیار دقیق که به رشد پایدار پروژه کمک کند، کافی نیست.
دلیل این امر، البته، این است که تعداد کمتری از پروژه‌ها به مراحل بعدی می‌رسند، بیشتر به این دلیل که کوچک هستند و توسعه قبل از بزرگ شدن پروژه به پایان می‌رسد. بنابراین توسعه‌دهندگان بیشتر با مشکل باگ‌های نادیده گرفته شده مواجه می‌شوند تا هشدارهای کاذبی که پروژه را غرق می‌کنند و تمام تلاش‌های بازآرایی را مختل می‌کنند. و به همین دلیل، افراد به صورت متناسب بهینه‌سازی می‌کنند. با این حال، اگر روی یک پروژه متوسط ​​تا بزرگ کار می‌کنید، باید به هر دو مشکل false negative (باگ‌های نادیده گرفته شده) و false positive (هشدارهای کاذب) توجه مساوی داشته باشید.
4\.3 ستون‌های سوم و چهارم: بازخورد سریع و قابلیت نگهداری
در این بخش، درباره دو ستون باقی‌مانده یک تست واحد خوب صحبت می‌کنیم:
\- بازخورد سریع
\- قابلیت نگهداری
همان‌طور که از فصل 2 به یاد دارید، بازخورد سریع یک ویژگی ضروری برای یک تست واحد است. هرچه تست‌ها سریع‌تر اجرا شوند، تعداد بیشتری از آن‌ها را می‌توانید در مجموعه تست‌ها داشته باشید و آن‌ها را بیشتر اجرا کنید.
با تست‌هایی که سریع اجرا می‌شوند، می‌توانید حلقه بازخورد را به طور قابل توجهی کوتاه کنید، تا جایی که تست‌ها بلافاصله پس از شکستن کد، شما را از باگ‌ها آگاه می‌کنند، در نتیجه هزینه رفع آن‌ها تقریباً به صفر می‌رسد. از سوی دیگر، تست‌های کند بازخورد را به تأخیر می‌اندازند و احتمالاً دوره‌ای را که باگ‌ها نادیده گرفته می‌شوند طولانی‌تر می‌کنند، در نتیجه هزینه رفع آن‌ها را افزایش می‌دهند. زیرا تست‌های کند شما را از اجرای مکرر آن‌ها منصرف می‌کنند و بنابراین منجر به اتلاف وقت بیشتری در حرکت در جهت نادرست می‌شوند.

**80** CHAPTER 4 ***The four pillars of a good unit test***

در نهایت، چهارمین ستون تست‌های واحد خوب، معیار قابلیت نگهداری (maintainability) است که هزینه‌های نگهداری را ارزیابی می‌کند. این معیار شامل دو جزء اصلی است:
\-  \*\*چقدر سخت است که تست را فهمید\*\* - این جزء به اندازه تست مربوط می‌شود. هرچه خطوط کد در تست کمتر باشد، تست قابل خواندن‌تر است. همچنین تغییر یک تست کوچک در صورت نیاز آسان‌تر است. البته، این به شرطی است که شما سعی نکنید به طور مصنوعی کد تست را فشرده کنید تا فقط تعداد خطوط را کاهش دهید. کیفیت کد تست به اندازه کد تولیدی اهمیت دارد. در نوشتن تست‌ها کوتاه نیاورید و کد تست را به عنوان یک شهروند درجه یک در نظر بگیرید.
\-  \*\*چقدر سخت است که تست را اجرا کنید\*\* - اگر تست با وابستگی‌های خارج از فرآیند (out-of-process) کار کند، باید زمانی را صرف نگه‌داشتن این وابستگی‌ها کنید: راه‌اندازی مجدد سرور پایگاه داده، حل مشکلات اتصال شبکه و غیره.
\### 4.4 در جستجوی تست ایده‌آل
در اینجا دوباره چهار ویژگی یک تست واحد خوب آورده شده است:
\- حفاظت در برابر رگرسیون‌ها
\- مقاومت در برابر بازآرایی
\- بازخورد سریع
\- قابلیت نگهداری
این چهار ویژگی، وقتی با هم ضرب شوند، ارزش یک تست را تعیین می‌کنند. و منظور از ضرب شدن در معنای ریاضی آن است؛ یعنی اگر یک تست در یکی از ویژگی‌ها نمره صفر بگیرد، ارزش آن نیز به صفر می‌رسد:
\```
Value estimate = [0..1] \* [0..1] \* [0..1] \* [0..1]
\```

\*\*نکته:\*\* برای اینکه تست ارزشمند باشد، باید در همه چهار دسته حداقل مقداری نمره کسب کند.
البته، اندازه‌گیری دقیق این ویژگی‌ها غیرممکن است. هیچ ابزار تحلیل کدی وجود ندارد که بتوانید تست را به آن وصل کنید و اعداد دقیقی بگیرید. اما شما هنوز هم می‌توانید تست را به طور دقیق ارزیابی کنید تا ببینید تست در مورد چهار ویژگی کجا ایستاده است. این ارزیابی به نوبه خود به شما تخمینی از ارزش تست می‌دهد که می‌توانید از آن برای تصمیم‌گیری درباره نگه‌داشتن تست در مجموعه استفاده کنید.
به یاد داشته باشید، تمام کدها، از جمله کدهای تست، یک بدهی هستند. یک آستانه نسبتاً بالا برای حداقل ارزش مورد نیاز تعیین کنید و فقط اجازه دهید تست‌ها در مجموعه باشند اگر این آستانه را برآورده کنند. تعداد کمی از تست‌های بسیار ارزشمند کار بسیار بهتری در نگه‌داشتن رشد پروژه انجام می‌دهند تا تعداد زیادی از تست‌های متوسط.
به زودی چند مثال را نشان خواهم داد. فعلاً، بیایید بررسی کنیم که آیا امکان ایجاد یک تست ایده‌آل وجود دارد یا خیر.

***In search of an ideal test* 81**
\### 4.4.1 آیا امکان ایجاد یک تست ایده‌آل وجود دارد؟
یک تست ایده‌آل تستی است که در تمام چهار ویژگی امتیاز کامل کسب کند. اگر مقادیر حداقل و حداکثر را به ترتیب 0 و 1 برای هر یک از ویژگی‌ها در نظر بگیریم، یک تست ایده‌آل باید در همه آن‌ها امتیاز 1 کسب کند.

متأسفانه، ایجاد چنین تست ایده‌آلی غیرممکن است. دلیل آن این است که سه ویژگی اول—حفاظت در برابر رگرسیون‌ها، مقاومت در برابر بازآرایی و بازخورد سریع—با یکدیگر ناسازگار هستند. امکان حداکثرسازی همه آن‌ها وجود ندارد: شما باید یکی از سه ویژگی را فدا کنید تا دو ویژگی باقی‌مانده را به حداکثر برسانید.
علاوه بر این، به دلیل اصل ضرب (به محاسبه ارزش تخمینی در بخش قبلی مراجعه کنید)، حفظ تعادل حتی سخت‌تر می‌شود. شما نمی‌توانید فقط یکی از ویژگی‌ها را کنار بگذارید تا روی بقیه تمرکز کنید. همانطور که قبلاً اشاره کردم، تستی که در یکی از چهار دسته امتیاز صفر بگیرد بی‌ارزش است. بنابراین، باید این ویژگی‌ها را به گونه‌ای به حداکثر برسانید که هیچ یک از آن‌ها بیش از حد کاهش نیابد.
بیایید به چند مثال از تست‌هایی که دو ویژگی از سه ویژگی را به حداکثر رسانده‌اند و ویژگی سوم را قربانی کرده‌اند و در نتیجه ارزش آن‌ها نزدیک به صفر است، نگاه کنیم.
\### 4.4.2 مورد افراطی شماره 1: تست‌های انتها به انتها
اولین مثال، تست‌های انتها به انتها (End-to-End) است. همانطور که ممکن است از فصل 2 به یاد داشته باشید، تست‌های انتها به انتها از دید کاربر نهایی به سیستم نگاه می‌کنند. این تست‌ها معمولاً از تمامی اجزای سیستم، از جمله رابط کاربری، پایگاه داده و برنامه‌های خارجی عبور می‌کنند.
از آنجا که تست‌های انتها به انتها مقدار زیادی از کد را اجرا می‌کنند، بهترین حفاظت را در برابر رگرسیون‌ها ارائه می‌دهند. در واقع، از بین همه نوع تست‌ها، تست‌های انتها به انتها بیشترین کد را اجرا می‌کنند—هم کد شما و هم کدی که شما ننوشته‌اید اما در پروژه استفاده می‌کنید، مانند کتابخانه‌های خارجی، فریم‌ورک‌ها و برنامه‌های شخص ثالث.
تست‌های انتها به انتها همچنین به خطاهای مثبت کاذب مقاوم هستند و بنابراین مقاومت خوبی در برابر بازآرایی دارند. اگر بازآرایی به درستی انجام شود، رفتار قابل مشاهده سیستم تغییر نمی‌کند و بنابراین بر تست‌های انتها به انتها تأثیری نمی‌گذارد. این یکی دیگر از مزایای این تست‌ها است: آن‌ها هیچ پیاده‌سازی خاصی را تحمیل نمی‌کنند. تنها چیزی که تست‌های انتها به انتها به آن نگاه می‌کنند، نحوه عملکرد یک ویژگی از دید کاربر نهایی است. این تست‌ها تا حد امکان از جزئیات پیاده‌سازی فاصله دارند.
با این حال، با وجود این مزایا، تست‌های انتها به انتها یک عیب عمده دارند: آن‌ها کند هستند. هر سیستمی که تنها به این تست‌ها متکی باشد، در گرفتن بازخورد سریع با مشکل مواجه خواهد شد. و این برای بسیاری از تیم‌های توسعه یک مشکل اساسی است. به همین دلیل، تقریباً غیرممکن است که کل کد خود را فقط با تست‌های انتها به انتها پوشش دهید.
شکل 4.6 نشان می‌دهد که تست‌های انتها به انتها از نظر سه معیار اول تست‌های واحد کجا قرار دارند. این تست‌ها حفاظت عالی در برابر خطاهای رگرسیونی و مثبت کاذب ارائه می‌دهند، اما سرعت ندارند.
**82** CHAPTER 4 ***The four pillars of a good unit test***
<p align="center">
    <img src="../Part 4/Images/4.6.png" />
</p>

مثال دیگری از حداکثرسازی دو ویژگی از سه ویژگی به قیمت از دست دادن ویژگی سوم، تست‌های ساده هستند. این تست‌ها یک قطعه کد ساده را پوشش می‌دهند، چیزی که به دلیل سادگی بیش از حد احتمالاً خراب نمی‌شود، همانطور که در لیست زیر نشان داده شده است.
```c#
public class User
{
public string Name { get; set; }
}
[Fact]
public void Test()
{
var sut = new User();
sut.Name = "John Smith";
Assert.Equal("John Smith", sut.Name);
}
```

برخلاف تست‌های انتها به انتها، تست‌های ساده بازخورد سریعی ارائه می‌دهند—آن‌ها بسیار سریع اجرا می‌شوند. همچنین احتمال تولید یک مثبت کاذب در آن‌ها بسیار کم است، بنابراین مقاومت خوبی در برابر بازآرایی دارند. اما تست‌های ساده به احتمال زیاد هیچ رگرسیونی را آشکار نمی‌کنند، زیرا فضای زیادی برای اشتباه در کد پایه وجود ندارد.

  
تست‌های ساده وقتی به حد افراطی برسند، به تست‌های توتولوژی تبدیل می‌شوند. این تست‌ها هیچ چیزی را آزمایش نمی‌کنند زیرا به گونه‌ای تنظیم شده‌اند که همیشه موفق باشند یا حاوی ادعاهای بی‌معنای معنایی باشند.

***In search of an ideal test* 83**
<p align="center">
    <img src="../Part 4/Images/4.7.png" />
</p>

شکل 4.7 نشان می‌دهد که تست‌های ساده در کجا قرار دارند. آن‌ها مقاومت خوبی در برابر بازآرایی دارند و بازخورد سریعی ارائه می‌دهند، اما شما را از رگرسیون‌ها محافظت نمی‌کنند.

\### 4.4.4 مورد افراطی شماره 3: تست‌های شکننده
به طور مشابه، نوشتن تستی که سریع اجرا شود و احتمال زیادی برای کشف رگرسیون داشته باشد، اما با تعداد زیادی مثبت کاذب همراه باشد، بسیار آسان است. چنین تستی به نام تست شکننده شناخته می‌شود: این تست نمی‌تواند بازآرایی را تحمل کند و صرف نظر از اینکه عملکرد پایه شکسته باشد یا نه، قرمز می‌شود.
قبلاً یک مثال از تست شکننده را در لیست 4.2 دیدید. اینجا یک مثال دیگر وجود دارد.
```c#
public class UserRepository

  

{

  

public User GetById(int id)
{
/\* ... \*/
}
public string LastExecutedSqlStatement { get; set; }
}
[Fact]
public void GetById\_executes\_correct\_SQL\_code()
{
var sut = new UserRepository();
User user = sut.GetById(5);
Assert.Equal(
"SELECT \* FROM dbo.[User] WHERE UserID = 5",
sut.LastExecutedSqlStatement);
}
```

CHAPTER 4 ***The four pillars of a good unit test 84***

این تست اطمینان حاصل می‌کند که کلاس UserRepository یک دستور SQL صحیح برای واکشی یک کاربر از پایگاه داده تولید می‌کند. آیا این تست می‌تواند باگ را شناسایی کند؟ بله، می‌تواند. برای مثال، یک توسعه‌دهنده ممکن است در تولید کد SQL اشتباه کند و به اشتباه به جای UserID از ID استفاده کند، و این تست با نشان دادن خطا به این موضوع اشاره خواهد کرد. اما آیا این تست در برابر تغییرات بازآرایی مقاوم است؟ اصلاً نه. در اینجا چندین تغییر مختلف از دستور SQL آورده شده است که همگی به نتیجه یکسان منجر می‌شوند:

```sql
SELECT \* FROM dbo.[User] WHERE UserID = 5
SELECT \* FROM dbo.User WHERE UserID = 5
SELECT UserID, Name, Email FROM dbo.[User] WHERE UserID = 5
SELECT \* FROM dbo.[User] WHERE UserID = @UserID
```

تستی که در لیستینگ ۴.۶ آمده است، اگر اسکریپت SQL را به هر یک از این تغییرات تبدیل کنید، خطا خواهد داد، حتی اگر خود عملکرد بدون مشکل باقی بماند. این نیز یک نمونه از اتصال تست به جزئیات داخلی پیاده‌سازی SUT است. این تست به جای تمرکز بر چیستی، بر چگونگی‌ها تمرکز دارد و بنابراین جزئیات پیاده‌سازی SUT را در خود تثبیت می‌کند و مانع از هرگونه بازآرایی بیشتر می‌شود.

شکل ۴.۸ نشان می‌دهد که تست‌های شکننده به دسته سوم تعلق دارند. این تست‌ها سریع اجرا می‌شوند و محافظت خوبی در برابر رگرسیون‌ها ارائه می‌دهند اما مقاومت کمی در برابر بازآرایی دارند.

<p align="center">
    <img src="../Part 4/Images/4.8.png" />
</p>

در جستجوی یک تست ایده‌آل: نتایج

سه ویژگی اصلی یک تست خوب (محافظت در برابر رگرسیون‌ها، مقاومت در برابر بازآرایی، و بازخورد سریع) با یکدیگر ناسازگار هستند. در حالی که تهیه یک تست که دو مورد از این سه ویژگی را به حداکثر برساند، نسبتا آسان است، اما این کار همیشه به بهای از دست دادن ویژگی سوم تمام می‌شود. متأسفانه، به دلیل اصل ضرب، چنین تستی ارزشی نزدیک به صفر خواهد داشت. به همین دلیل، ایجاد یک تست ایده‌آل که در هر سه ویژگی امتیاز کامل بگیرد، غیرممکن است (شکل 4.9).

***In search of an ideal test* 85**
<p align="center">
    <img src="../Part 4/Images/4.9.png" />
</p>

ویژگی چهارم، یعنی قابلیت نگهداری، با سه ویژگی اول همبستگی ندارد، به‌جز در مورد تست‌های انتها به انتها (end-to-end). تست‌های انتها به انتها معمولاً به دلیل نیاز به تنظیم تمام وابستگی‌هایی که این تست‌ها به آن‌ها دسترسی دارند، حجم بزرگ‌تری دارند. همچنین این تست‌ها نیازمند تلاش اضافی برای نگهداری این وابستگی‌ها هستند. از این رو، تست‌های انتها به انتها معمولاً از نظر هزینه‌های نگهداری گران‌تر هستند.
نگه داشتن تعادل بین ویژگی‌های یک تست خوب دشوار است. یک تست نمی‌تواند در هر یک از سه دسته‌ی اول امتیاز حداکثر داشته باشد، و همچنین باید به جنبه‌ی قابلیت نگهداری هم توجه کنید تا تست به اندازه‌ی کافی کوتاه و ساده باقی بماند. بنابراین، مجبور به انجام مصالحه هستید. به علاوه، باید این مصالحه‌ها را به گونه‌ای انجام دهید که هیچ ویژگی خاصی به صفر نرسد. این فداکاری‌ها باید جزئی و استراتژیک باشند
این فداکاری‌ها چگونه باید باشند؟ به دلیل ناسازگاری محافظت در برابر رگرسیون‌ها، مقاومت در برابر بازآرایی و بازخورد سریع، ممکن است فکر کنید که بهترین استراتژی این است که از هر کدام کمی چشم‌پوشی کنید: فقط به اندازه‌ای که جا برای هر سه ویژگی باز شود.
در واقعیت، مقاومت در برابر بازآرایی غیرقابل مذاکره است. شما باید سعی کنید که تا جایی که می‌توانید از این ویژگی بهره‌مند شوید، به شرطی که تست‌های شما به طور معقولی سریع باقی بمانند و از استفاده انحصاری از تست‌های انتها به انتها پرهیز کنید. پس فداکاری به انتخاب بین میزان محافظت تست‌ها از اشکالات و سرعت آن‌ها در انجام این کار خلاصه می‌شود: یعنی انتخاب بین محافظت در برابر رگرسیون‌ها و بازخورد سریع. شما می‌توانید این انتخاب را به عنوان یک لغزنده تصور کنید که می‌تواند آزادانه بین محافظت در برابر رگرسیون‌ها و بازخورد سریع حرکت کند. هر چه در یکی از این ویژگی‌ها بیشتر پیشرفت کنید، در دیگری بیشتر از دست می‌دهید (شکل 4.10 را ببینید).
دلیل غیرقابل مذاکره بودن مقاومت در برابر بازآرایی این است که آیا یک تست این ویژگی را دارد یا نه، بیشتر یک انتخاب باینری است: تست یا مقاومت در برابر بازآرایی دارد یا ندارد. تقریباً هیچ مرحله‌ی میانی در بین آن‌ها وجود ندارد. بنابراین، نمی‌توانید از این ویژگی چشم‌پوشی کنید.
**86** CHAPTER 4 ***The four pillars of a good unit test***
<p align="center">
    <img src="../Part 4/Images/4.10.png" />
</p>

شکل 4.10 نشان می‌دهد که بهترین تست‌ها حداکثر قابلیت نگهداری و مقاومت در برابر بازآرایی را دارند؛ همیشه سعی کنید این دو ویژگی را به حداکثر برسانید. مصالحه در اینجا به انتخاب بین محافظت در برابر رگرسیون‌ها و بازخورد سریع ختم می‌شود.
فقط کمی مقاومت در برابر بازآرایی داشته باشید: شما باید تمام آن را از دست بدهید. از سوی دیگر، معیارهای محافظت در برابر رگرسیون‌ها و بازخورد سریع بیشتر قابل تنظیم هستند. در بخش بعدی خواهید دید که چه نوع مصالحه‌هایی ممکن است وقتی یکی را بر دیگری ترجیح دهید.

\*\*نکته:\*\* از بین بردن شکنندگی (خطاهای مثبت کاذب) در تست‌ها اولین اولویت در مسیر دستیابی به یک مجموعه تست قدرتمند است.
\*\*قضیه‌ی CAP\*\*
مصالحه بین سه ویژگی اول یک تست واحد خوب شبیه به قضیه‌ی CAP است. این قضیه بیان می‌کند که برای یک سیستم ذخیره‌سازی توزیع‌شده غیرممکن است که همزمان بیش از دو مورد از سه تضمین زیر را فراهم کند:
\-  \*\*یکنواختی (Consistency):\*\* به این معنی که هر خواندنی جدیدترین نوشتار را دریافت می‌کند یا با خطا مواجه می‌شود.
\-  \*\*دسترسی‌پذیری (Availability):\*\* به این معنی که هر درخواست پاسخی دریافت می‌کند (به‌جز مواردی که تمامی گره‌ها در سیستم تحت تاثیر قطعی قرار می‌گیرند).
\-  \*\*تحمل تقسیم (Partition tolerance):\*\* به این معنی که سیستم همچنان به کار خود ادامه می‌دهد، حتی اگر اتصال بین گره‌های شبکه از دست برود.
شباهت‌ها دو جنبه دارند:
\- اول، یک مصالحه‌ی دو از سه.
\- دوم، مؤلفه‌ی تحمل تقسیم در سیستم‌های توزیع‌شده بزرگ نیز غیرقابل مذاکره است. یک برنامه بزرگ مانند، به عنوان مثال، وبسایت آمازون نمی‌تواند بر روی یک ماشین واحد کار کند. گزینه‌ی ترجیح دادن یکنواختی و دسترسی‌پذیری به هزینه‌ی تحمل تقسیم به سادگی روی میز نیست—آمازون داده‌های زیادی برای ذخیره بر روی یک سرور واحد دارد، هر چقدر هم که آن سرور بزرگ باشد.

***Exploring well-known test automation concepts* 87**

بنابراین انتخاب نیز به یک مصالحه بین یکنواختی و دسترسی‌پذیری ختم می‌شود. در برخی از بخش‌های سیستم، بهتر است کمی از یکنواختی چشم‌پوشی شود تا دسترسی‌پذیری بیشتری به دست آید. به عنوان مثال، هنگام نمایش یک کاتالوگ محصول، معمولاً اشکالی ندارد اگر برخی از قسمت‌های کاتالوگ به‌روز نباشند. در این سناریو، دسترسی‌پذیری اولویت بیشتری دارد. از سوی دیگر، هنگام به‌روزرسانی یک توضیح محصول، یکنواختی مهم‌تر از دسترسی‌پذیری است: گره‌های شبکه باید بر سر جدیدترین نسخه‌ی آن توضیح به توافق برسند تا از بروز conflict در ادغام جلوگیری شود.

\*\*4.5 بررسی مفاهیم شناخته‌شده در اتوماسیون تست\*\*

ویژگی‌های چهارگانه‌ای که قبلاً برای یک تست خوب معرفی شدند، مبنای اصلی هستند. تمام مفاهیم شناخته‌شده در اتوماسیون تست به این چهار ویژگی برمی‌گردند. در این بخش، به دو مفهوم معروف خواهیم پرداخت: هرم تست و تست‌های جعبه‌سفید در مقابل تست‌های جعبه‌سیاه.

\*\*4.5.1 تجزیه هرم تست\*\*
هرم تست مفهومی است که نسبت معینی از انواع مختلف تست‌ها را در مجموعه تست‌ها توصیه می‌کند (شکل 4.11):

\- Unit tests (تست‌های واحد)
\- Integration tests (تست‌های یکپارچگی)
\- End-to-end tests (تست‌های انتها به انتها)

هرم تست اغلب به صورت بصری به شکل هرم با این سه نوع تست نمایش داده می‌شود. عرض لایه‌های هرم به معنی شیوع نوع خاصی از تست‌ها است.
<p align="center">
    <img src="../Part 4/Images/4.11.png" />
</p>

**88** CHAPTER 4 ***The four pillars of a good unit test***

 
عرض لایه‌های هرم نشان‌دهنده تعداد تست‌ها است. هرچه لایه عریض‌تر باشد، تعداد تست‌ها بیشتر است. ارتفاع لایه‌ها معیاری است برای نزدیک بودن این تست‌ها به شبیه‌سازی رفتار کاربر نهایی. تست‌های End-to-end در بالای هرم قرار دارند و نزدیک‌ترین تست‌ها به تجربه کاربری هستند.
انواع مختلف تست‌ها در هرم انتخاب‌های متفاوتی در رابطه با trade-off بین فیدبک سریع و حفاظت در برابر رگرسیون‌ها دارند. تست‌های در لایه‌های بالاتر هرم بیشتر به حفاظت در برابر رگرسیون‌ها تمایل دارند، در حالی که لایه‌های پایین‌تر بر سرعت اجرای تست تأکید دارند (شکل 4.12).
<p align="center">
    <img src="../Part 4/Images/4.12.png" />
</p>

 
شکل 4.12 انواع مختلف تست‌ها در هرم انتخاب‌های متفاوتی بین فیدبک سریع و حفاظت در برابر رگرسیون‌ها دارند. تست‌های End-to-end به حفاظت در برابر رگرسیون‌ها تمایل دارند، تست‌های واحد (Unit Tests) بر فیدبک سریع تأکید دارند و تست‌های یکپارچگی (Integration Tests) در میانه این دو قرار دارند.
توجه داشته باشید که هیچ لایه‌ای از مقاومت در برابر refactoring چشم‌پوشی نمی‌کند. به طور طبیعی، تست‌های End-to-end و Integration نسبت به Unit Tests در این معیار امتیاز بالاتری دارند، اما این تنها به دلیل جدا بودن بیشتر آن‌ها از کد تولید است. با این حال، حتی Unit Tests نیز نباید مقاومت در برابر refactoring را فدای چیزی کنند. تمام تست‌ها باید هدفشان کاهش هر چه بیشتر false positives باشد، حتی وقتی که مستقیماً با کد تولید کار می‌کنند. (چگونگی انجام این کار موضوع فصل بعد است.)
ترکیب دقیق بین انواع تست‌ها برای هر تیم و پروژه متفاوت خواهد بود. اما به طور کلی، باید شکل هرم را حفظ کند: تست‌های End-to-end باید اقلیت باشند؛ Unit Tests اکثریت؛ و تست‌های Integration در جایی در میان این دو.
دلیل این که تست‌های End-to-end اقلیت هستند، بار دیگر به قانون ضرب اشاره شده در بخش 4.4 برمی‌گردد. تست‌های End-to-end امتیاز بسیار پایینی در معیار فیدبک سریع دارند. آن‌ها همچنین از نظر نگهداری مشکل دارند: معمولاً بزرگ‌تر هستند و نیاز به تلاش اضافی برای نگهداری وابستگی‌های خارج از فرآیند دارند. بنابراین، تست‌های End-to-end تنها در مورد عملکردهای حیاتی—ویژگی‌های کلیدی—مفید هستند.

***Exploring well-known test automation concepts* 89**
که شما نمی‌خواهید هیچ گونه باگی را در آن‌ها مشاهده کنید—و تنها زمانی که نمی‌توانید همان درجه از حفاظت را با Unit Tests یا Integration Tests به دست آورید. استفاده از تست‌های End-to-end برای هر چیز دیگری نباید از آستانه ارزش مورد نیاز شما عبور کند. Unit Tests معمولاً متعادل‌تر هستند و بنابراین معمولاً تعداد بیشتری از آن‌ها وجود دارد.

استثناهایی برای Test Pyramid وجود دارد. به عنوان مثال، اگر تمام کاری که برنامه شما انجام می‌دهد، عملیات‌های پایه‌ای ایجاد، خواندن، به‌روزرسانی و حذف (CRUD) با تعداد کمی قانون کسب‌وکار یا پیچیدگی دیگری باشد، هرم تست شما احتمالاً شبیه به یک مستطیل با تعداد مساوی از Unit Tests و Integration Tests و بدون تست‌های End-to-end خواهد بود.

Unit Tests در محیطی بدون پیچیدگی الگوریتمی یا کسب‌وکار کمتر مفید هستند—آن‌ها به سرعت به تست‌های پیش‌پاافتاده تبدیل می‌شوند. در عین حال، Integration Tests ارزش خود را حفظ می‌کنند—تأیید چگونگی عملکرد کد، هرچقدر هم که ساده باشد، در ارتباط با دیگر زیرسیستم‌ها، مانند پایگاه داده، هنوز مهم است. در نتیجه، ممکن است با تعداد کمتری از Unit Tests و تعداد بیشتری از Integration Tests مواجه شوید. در مثال‌های بسیار پیش‌پاافتاده، تعداد Integration Tests حتی ممکن است بیشتر از تعداد Unit Tests باشد.


استثنای دیگری برای Test Pyramid، API است که به یک وابستگی خارج از فرآیند واحد—مثلاً پایگاه داده—دسترسی دارد. داشتن تعداد بیشتری از تست‌های End-to-end ممکن است برای چنین برنامه‌ای گزینه مناسبی باشد. از آنجا که رابط کاربری وجود ندارد، تست‌های End-to-end به طور معقولی سریع اجرا خواهند شد. هزینه‌های نگهداری نیز زیاد نخواهد بود، زیرا تنها با یک وابستگی خارجی، پایگاه داده، کار می‌کنید. اساساً، تست‌های End-to-end در این محیط از تست‌های Integration متمایز نمی‌شوند. تنها تفاوت این است که تست‌های End-to-end نیاز به میزبانی برنامه در جایی دارند تا به طور کامل رفتار کاربر نهایی را شبیه‌سازی کنند، در حالی که تست‌های Integration معمولاً برنامه را در همان فرآیند میزبانی می‌کنند. ما در فصل 8 دوباره به Test Pyramid باز خواهیم گشت، زمانی که درباره Integration Testing صحبت خواهیم کرد.

\### 4.5.2 انتخاب بین تست‌های Black-box و White-box

مفهوم دیگر معروف تست اتوماسیون، تست‌های Black-box و White-box است. در این بخش، نشان می‌دهم که هر یک از این دو رویکرد چه زمانی باید استفاده شوند:

\-  \*\*تست Black-box\*\* روشی از تست نرم‌افزار است که به بررسی عملکرد یک سیستم بدون دانستن ساختار داخلی آن می‌پردازد. این نوع تست معمولاً بر اساس مشخصات و نیازها ساخته می‌شود: آنچه که برنامه باید انجام دهد، به جای اینکه چگونه آن را انجام می‌دهد.

\-  \*\*تست White-box\*\* معکوس این است. این یک روش تست است که به بررسی عملکرد داخلی برنامه می‌پردازد. تست‌ها از کد منبع استخراج می‌شوند، نه از نیازها یا مشخصات.
برای هر یک از این روش‌ها مزایا و معایب وجود دارد. تست White-box معمولاً دقیق‌تر است. با تحلیل کد منبع، می‌توانید بسیاری از خطاهایی را که ممکن است هنگام تکیه تنها بر مشخصات خارجی از دست بدهید، کشف کنید. از طرف دیگر، تست‌های ناشی از تست White-box اغلب شکننده هستند، زیرا تمایل دارند به پیاده‌سازی خاص کد تحت تست به طور نزدیکی متصل شوند. چنین تست‌هایی تعداد زیادی false positives تولید می‌کنند و بنابراین در معیار مقاومت در برابر refactoring ضعیف هستند. همچنین، معمولاً نمی‌توانند پیگیری شوند...

**90** CHAPTER 4 ***The four pillars of a good unit test***

بازگشت به رفتاری که برای یک فرد تجاری معنادار باشد، نشانه‌ای قوی است که این تست‌ها شکننده هستند و ارزش زیادی اضافه نمی‌کنند. تست‌های Black-box مزایا و معایب متضادی را ارائه می‌دهند (جدول 4.1).

**جدول 4.1: مزایا و معایب تست‌های White-box و Black-box**

|**ویژگی**|**تست White-box**|**تست Black-box**|
| :- | :- | :- |
|**مزایا**|- امکان بررسی دقیق‌تر و جامع‌تر کد منبع<br>- شناسایی خطاهای مخفی در منطق و ساختار کد|- تست عملکرد سیستم بر اساس نیازمندی‌ها و مشخصات<br>- استقلال از جزئیات پیاده‌سازی کد|
|**معایب**|- شکننده و حساس به تغییرات در پیاده‌سازی<br>- تولید خطاهای کاذب زیاد<br>- دشواری در پیوند با رفتارهای تجاری|- عدم توانایی در شناسایی مشکلات داخلی کد<br>- ممکن است تست‌ها نسبت به تغییرات کد پایدار نباشند|

**توضیحات**

-  **تست White-box**: این نوع تست به بررسی جزئیات داخلی کد می‌پردازد و امکان شناسایی مشکلات پیچیده‌ای که در تست‌های Black-box ممکن است نادیده گرفته شوند را فراهم می‌کند. با این حال، به دلیل وابستگی به پیاده‌سازی کد، ممکن است تغییرات در کد منجر به شکست تست‌ها شود و تست‌ها اغلب نمی‌توانند با رفتارهای تجاری معنی‌دار پیوند پیدا کنند.

-  **تست Black-box**: این نوع تست بر اساس مشخصات و نیازمندی‌ها عملکرد سیستم را ارزیابی می‌کند، بدون نیاز به دانستن جزئیات داخلی کد. این تست‌ها به دلیل استقلال از پیاده‌سازی کد معمولاً پایدارتر هستند، اما ممکن است نتوانند مشکلات داخلی کد را شناسایی کنند.

به یاد داشته باشید که از بخش 4.4.5، نمی‌توانید در مورد مقاومت در برابر تغییرات کد سازش کنید: یک تست یا مقاومت در برابر تغییرات را دارد یا ندارد. بنابراین، به طور پیش‌فرض، تست‌های Black-box را بر تست‌های White-box ترجیح دهید. همه تست‌ها—چه واحد، یکپارچه‌سازی، یا end-to-end—باید سیستم را به عنوان یک جعبه سیاه مشاهده کرده و رفتارهای معنادار در دامنه مسئله را تأیید کنند. اگر نمی‌توانید یک تست را به یک نیازمندی تجاری ردیابی کنید، این نشان‌دهنده شکنندگی تست است. این تست را بازسازی یا حذف کنید؛ اجازه ندهید که به صورت فعلی وارد مجموعه تست‌ها شود. تنها استثنا زمانی است که تست کدهای کاربردی با پیچیدگی الگوریتمی بالا را پوشش می‌دهد (بیشتر در فصل 7).

توجه داشته باشید که حتی اگر تست‌های Black-box هنگام نوشتن تست‌ها ترجیح داده می‌شوند، می‌توانید همچنان از روش White-box هنگام تحلیل تست‌ها استفاده کنید. از ابزارهای پوشش کد برای مشاهده کدام بخش‌های کد اجرا نشده‌اند استفاده کنید، اما سپس به آنها به گونه‌ای تست کنید که گویی چیزی در مورد ساختار داخلی کد نمی‌دانید. ترکیب چنین روش‌های White-box و Black-box بهترین عملکرد را دارد.

\### خلاصه

\-  \*\*یک تست واحد خوب\*\* چهار ویژگی اساسی دارد که می‌توانید برای تحلیل هر تست خودکار، چه واحد، یکپارچه‌سازی، یا end-to-end، از آنها استفاده کنید:

` `- حفاظت در برابر بازگشت به خطاها
` `- مقاومت در برابر تغییرات
` `- بازخورد سریع
` `- نگهداری
\-  \*\*حفاظت در برابر بازگشت به خطاها\*\* معیاری است برای سنجش میزان قدرت تست در نشان دادن وجود اشکالات (بازگشت به خطاها). هرچه کد بیشتری توسط تست اجرا شود (هم کد شما و هم کد کتابخانه‌ها و چارچوب‌های مورد استفاده در پروژه)، احتمال اینکه تست اشکالی را نمایان کند بالاتر است.
\-  \*\*مقاومت در برابر تغییرات\*\* درجه‌ای است که تست می‌تواند تغییرات در کد برنامه را بدون تولید هشدارهای اشتباه حفظ کند.
\-  \*\*یک هشدار اشتباه\*\* یک زنگ خطر کاذب است—نتیجه‌ای که نشان می‌دهد تست شکست خورده است، در حالی که عملکردی که پوشش می‌دهد به درستی کار می‌کند. هشدارهای اشتباه می‌توانند تأثیر ویران‌کننده‌ای بر مجموعه تست‌ها داشته باشند:
` `- آنها توانایی و تمایل شما به واکنش به مشکلات در کد را کاهش می‌دهند، زیرا به هشدارهای کاذب عادت می‌کنید و دیگر به آنها توجه نمی‌کنید.
***Summary* 91**
\- آنها درک شما از تست‌ها به عنوان یک شبکه امنیتی قابل اعتماد را کاهش می‌دهند و باعث از دست دادن اعتماد به مجموعه تست‌ها می‌شوند.
\- هشدارهای اشتباه نتیجه ارتباط نزدیک بین تست‌ها و جزئیات پیاده‌سازی داخلی سیستم تحت تست است. برای جلوگیری از چنین ارتباطی، تست باید نتیجه نهایی که SUT تولید می‌کند را تأیید کند، نه مراحل انجام آن.
\- حفاظت در برابر بازگشت به خطاها و مقاومت در برابر تغییرات به دقت تست کمک می‌کنند. یک تست دقیق است که سیگنال قوی (قادر به یافتن اشکالات، حوزه حفاظت در برابر بازگشت به خطاها) با کمترین نویز (هشدارهای اشتباه) تولید کند (حوزه مقاومت در برابر تغییرات).
\- هشدارهای اشتباه در ابتدای پروژه تأثیر منفی زیادی ندارند، اما با رشد پروژه اهمیت آنها به میزان هشدارهای منفی (اشکالات نادیده گرفته شده) افزایش می‌یابد.
\- بازخورد سریع معیاری است از اینکه تست چقدر سریع اجرا می‌شود.
\- نگهداری از دو مؤلفه تشکیل شده است:
` `- چقدر درک تست دشوار است. هرچه تست کوچکتر باشد، خواناتر است.
` `- چقدر اجرای تست دشوار است. هرچه تعداد وابستگی‌های برون‌فرایند کمتر باشد، نگهداری آنها آسان‌تر است.
\- تخمین ارزش یک تست حاصل‌ضرب امتیازهایی است که تست در هر یک از چهار ویژگی می‌گیرد. اگر تست در یکی از ویژگی‌ها امتیاز صفر بگیرد، ارزش آن نیز به صفر تبدیل می‌شود.


\- ایجاد تستی که در تمام چهار ویژگی بیشترین امتیاز را کسب کند، غیرممکن است، زیرا سه ویژگی اول—حفاظت در برابر بازگشت به خطاها، مقاومت در برابر تغییرات، و بازخورد سریع—به طور متقابل انحصاری هستند. تست فقط می‌تواند دو مورد از سه مورد را به حداکثر برساند.
\- مقاومت در برابر تغییرات غیرقابل مذاکره است، زیرا آیا تست این ویژگی را دارد یا ندارد، عمدتاً یک انتخاب باینری است: تست یا مقاومت در برابر تغییرات را دارد یا ندارد. سازش بین ویژگی‌ها به انتخاب بین حفاظت در برابر بازگشت به خطاها و بازخورد سریع برمی‌گردد.
\- هرم تست به نسبتی از تست‌های واحد، یکپارچه‌سازی، و end-to-end توصیه می‌کند: تست‌های end-to-end باید در اقلیت، تست‌های واحد در اکثریت، و تست‌های یکپارچه‌سازی در جایی در میان باشند.
 
\- انواع مختلف تست‌ها در هرم انتخاب‌های مختلفی بین بازخورد سریع و حفاظت در برابر بازگشت به خطاها می‌کنند. تست‌های end-to-end به حفاظت در برابر بازگشت به خطاها تمایل دارند، در حالی که تست‌های واحد به بازخورد سریع تمایل دارند.
\- از روش تست black-box هنگام نوشتن تست‌ها استفاده کنید. از روش white-box هنگام تحلیل تست‌ها استفاده کنید.

</div>